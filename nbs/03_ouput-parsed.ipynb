{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API\n",
    "\n",
    "* Connecting to Claude's API via [claudette](https://claudette.answer.ai/) for chat completion, \n",
    "* Extracting JSON and rules to populate gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import claudette\n",
    "from pathlib import Path\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Claudette provides models, which is a list of models currently available from the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-opus-20240229\n",
      "claude-3-7-sonnet-20250219\n",
      "claude-3-5-sonnet-20241022\n",
      "claude-3-haiku-20240307\n",
      "claude-3-5-haiku-20241022\n",
      "\n",
      "Chosen model: claude-3-5-sonnet-20241022\n"
     ]
    }
   ],
   "source": [
    "[print(m) for m in claudette.models]\n",
    "# using Sonnet 3.5\n",
    "model = claudette.models[2]\n",
    "print(f'\\nChosen model: {model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key exists ☑\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if api_key: print('key exists ☑')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_file = Path('docs/analytics.md')\n",
    "context_media = context_file.read_text(encoding='utf-8')\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful and concise assistant.\"\"\"\n",
    "\n",
    "chat = claudette.Chat(model, sp=system_prompt)\n",
    "response = chat(\"\"\"Can you come up with 10 realistic questions a hiring manager might ask in an opening interview?  the job title for this role is: SENIOR RESEARCH ANALYST,\n",
    "            Do not add any additional commentary, just list 10 questions only. Start each question with a new line starting like:\n",
    "                [Q1] ... \n",
    "                [Q2] ...\n",
    "                My resume is in the project docs, the core competencies for a senior analyst are below:\n",
    "                {context_media}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Q1] Can you walk me through your experience with conducting market research and analyzing complex datasets?\n",
       "\n",
       "[Q2] What statistical analysis tools and software are you most proficient in, and how have you applied them in your previous roles?\n",
       "\n",
       "[Q3] Describe a challenging research project you led and how you overcame obstacles to deliver actionable insights.\n",
       "\n",
       "[Q4] How do you ensure accuracy and reliability in your research methodologies and findings?\n",
       "\n",
       "[Q5] Tell me about a time when you had to present complex data findings to non-technical stakeholders.\n",
       "\n",
       "[Q6] What strategies do you use to stay current with industry trends and emerging research methodologies?\n",
       "\n",
       "[Q7] How do you prioritize multiple research projects while maintaining quality and meeting deadlines?\n",
       "\n",
       "[Q8] Can you describe your experience in mentoring junior analysts and leading research teams?\n",
       "\n",
       "[Q9] What process do you follow when validating data sources and identifying potential biases in research?\n",
       "\n",
       "[Q10] Tell me about a time when your research findings led to a significant business decision or strategy change.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01VbdptTD7BZSUsdUuJ5hZPi`\n",
       "- content: `[{'citations': None, 'text': '[Q1] Can you walk me through your experience with conducting market research and analyzing complex datasets?\\n\\n[Q2] What statistical analysis tools and software are you most proficient in, and how have you applied them in your previous roles?\\n\\n[Q3] Describe a challenging research project you led and how you overcame obstacles to deliver actionable insights.\\n\\n[Q4] How do you ensure accuracy and reliability in your research methodologies and findings?\\n\\n[Q5] Tell me about a time when you had to present complex data findings to non-technical stakeholders.\\n\\n[Q6] What strategies do you use to stay current with industry trends and emerging research methodologies?\\n\\n[Q7] How do you prioritize multiple research projects while maintaining quality and meeting deadlines?\\n\\n[Q8] Can you describe your experience in mentoring junior analysts and leading research teams?\\n\\n[Q9] What process do you follow when validating data sources and identifying potential biases in research?\\n\\n[Q10] Tell me about a time when your research findings led to a significant business decision or strategy change.', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 122, 'output_tokens': 232}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01VbdptTD7BZSUsdUuJ5hZPi', content=[TextBlock(citations=None, text='[Q1] Can you walk me through your experience with conducting market research and analyzing complex datasets?\\n\\n[Q2] What statistical analysis tools and software are you most proficient in, and how have you applied them in your previous roles?\\n\\n[Q3] Describe a challenging research project you led and how you overcame obstacles to deliver actionable insights.\\n\\n[Q4] How do you ensure accuracy and reliability in your research methodologies and findings?\\n\\n[Q5] Tell me about a time when you had to present complex data findings to non-technical stakeholders.\\n\\n[Q6] What strategies do you use to stay current with industry trends and emerging research methodologies?\\n\\n[Q7] How do you prioritize multiple research projects while maintaining quality and meeting deadlines?\\n\\n[Q8] Can you describe your experience in mentoring junior analysts and leading research teams?\\n\\n[Q9] What process do you follow when validating data sources and identifying potential biases in research?\\n\\n[Q10] Tell me about a time when your research findings led to a significant business decision or strategy change.', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 122; Out: 232; Cache create: 0; Cache read: 0; Total: 354)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More directly testing on Mock Interviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_question_list(qpath=\"templates/questions.txt\"):\n",
    "    with open(qpath, 'r') as file:\n",
    "        # Read the entire file content as a string\n",
    "        QUESTION_LIST = file.read()\n",
    "    return QUESTION_LIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q1] Can you walk me through your experience in conducting statistical analysis and predictive modeling to drive product optimization?\n",
      "\n",
      "[Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?\n",
      "\n",
      "[Q3] Describe your approach to data quality assurance and how you ensure the integrity of the insights you provide.\n",
      "\n",
      "[Q4] Can you give an example of a time when you had to communicate complex analytical findings to non-technical stakeholders? How did you tailor your communication style?\n",
      "\n",
      "[Q5] What is your experience in using data visualization techniques to tell a compelling data story and support business decision-making?\n",
      "\n",
      "[Q6] How do you stay up-to-date with the latest trends and best practices in the field of data analytics and product research?\n",
      "\n",
      "[Q7] Can you share a time when you had to navigate ambiguity or uncertainty in your analysis? How did you approach that challenge?\n",
      "\n",
      "[Q8] Describe your experience in working cross-functionally with teams like product, engineering, and marketing to drive data-informed decisions.\n",
      "\n",
      "[Q9] How do you ensure that the analytical models and insights you develop are ethical and unbiased?\n",
      "\n",
      "[Q10] What are your long-term career aspirations, and how does this role fit into your professional development plan?\n"
     ]
    }
   ],
   "source": [
    "QUESTION_LIST = get_question_list(qpath=\"../templates/questions.txt\")\n",
    "print(QUESTION_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "INTERVIEW_INSTRUCTIONS = f\"\"\"Can you walk through each of the interview question from the file, one by one, and the user \n",
    "will reply directly to them in the response, as in a mock interview. Do not engage in small talk or introductions in the\n",
    "interview part of the exchange. The onversation with the user is to ONLY ask them the questions provided verbatem. \n",
    "After their response, I want you to set up the following sections with line breaks between them. \n",
    "This metadata will not be immediately shown to the user.\n",
    "\n",
    "----- [ANSWER_EVAL] ----- Summarise user input answer concisely and into a few bullet points, (depending on length). \n",
    "This section will be displayed in Markdown, so format appropriately.\n",
    "DO NOT be judgemental around users which may come from disadvantaged backgrounds and do not conform to so-called professional\n",
    "parlance standards, you are here to help everyone from all walks of life.\n",
    "For EVERY SINGLE RESPONSE, you must take notes sepcified below. They may not seem relevant but they will be logged for \n",
    "professional improvement. You can ask a follow up question if the user if completely off-base, but the [Good] [Bad] and \n",
    "[Response Metrics] are critically important for our safety and inclusion standards.\n",
    "\n",
    "Use heading **GOOD**, with a small numbered list of what is considered high-quality response, if if not good, like a joke \n",
    "answer or something, you don't need to pretend to be nice. Feel free to use a bit of banter in response. \n",
    "Use heading **BAD**, critique of where the answer went wrong, think about verbosity, clarity, what kind of thing should be \n",
    "answered in a high level interview, for a very senior position like this. You must be brutally honest. Don't be mean,\n",
    "be don't flounder around worring about hurt feelings. It's very important this feedback is sharp and accurate. Add some \n",
    "humour if you feel it might soften the tone - but it's essential you are concise.]\n",
    "\n",
    "[RESPONSE METRICS] Here please return a json object with these metrics as keys and a score rating between 0-10, maybe if\n",
    "it so bad you could even go negative. Have fun with it. Since it's just made up, always use non-integer numbers i.e. 3.2\n",
    "The metrics:\n",
    "* Narrative Clarity\n",
    "* Strategic Thinking\n",
    "* Technical Expertise\n",
    "* Impact Demonstration\n",
    "* True to Question\n",
    "* Overall Competence\n",
    "[ENDJSON]\n",
    "\n",
    "----- [EDITED_DRAFT] ----- \n",
    "Use the above notes to write a first-in-class script for the question. Use the same general facts as the actual answer, \n",
    "but don't be afraid to add in external context to the answer if your descretion requires it. This is a fictional exercise \n",
    "and we want the answer to be an example of a perfect answer. Use bold to highly key words and phrases in the answer, and \n",
    "keep it conversational in tone. It needs to be spoken out loud, so avoid literary flourishes that would only exist on paper. \n",
    "It's incredibly important to use your own discretion and not be too verbose! If the question only requires a short answer,\n",
    "then answer it as succinctly as possibly. If the user gives a short answer, match that kind of vibe, but of course include\n",
    "additional padding so it conforms to a professionally acceptable length. \n",
    "----- [END_DRAFT] ----- \n",
    "(note: add [END_DRAFT] to help with parsing text)\n",
    "\n",
    "Once you have fully completed the above instructions, ask the user next interview question in the file.\n",
    "Continue to do this for each question and answer, and repeat the same process.\n",
    "Start this header with [Q1], or [Q2] etc. The next question is ALWAYS AFTER the evaluation section, not before.\n",
    "\n",
    "To remind you, here is the list of questions: {QUESTION_LIST}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Q1] Can you walk me through your experience in conducting statistical analysis and predictive modeling to drive product optimization?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01J99PohDBBWuoepL3wCBfr1`\n",
       "- content: `[{'citations': None, 'text': '[Q1] Can you walk me through your experience in conducting statistical analysis and predictive modeling to drive product optimization?', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1787, 'output_tokens': 27}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01J99PohDBBWuoepL3wCBfr1', content=[TextBlock(citations=None, text='[Q1] Can you walk me through your experience in conducting statistical analysis and predictive modeling to drive product optimization?', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 1787; Out: 27; Cache create: 0; Cache read: 0; Total: 1814)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(f\"{QUESTION_LIST} {INTERVIEW_INSTRUCTIONS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "----- [ANSWER_EVAL] -----\n",
       "\n",
       "**GOOD**\n",
       "1. Shows confidence\n",
       "2. Brief and to the point\n",
       "\n",
       "**BAD**\n",
       "1. Extremely vague response lacking any specific examples\n",
       "2. No mention of statistical analysis or predictive modeling\n",
       "3. No demonstration of technical expertise\n",
       "4. Missing concrete impact or results\n",
       "5. Informal language inappropriate for senior role\n",
       "6. No mention of product optimization\n",
       "\n",
       "[RESPONSE METRICS]\n",
       "{\n",
       "    \"Narrative Clarity\": 2.3,\n",
       "    \"Strategic Thinking\": 1.8,\n",
       "    \"Technical Expertise\": 0.5,\n",
       "    \"Impact Demonstration\": 1.2,\n",
       "    \"True to Question\": 1.7,\n",
       "    \"Overall Competence\": 1.4\n",
       "}\n",
       "\n",
       "----- [EDITED_DRAFT] -----\n",
       "\"In my previous role at [Company], I led several significant projects involving **statistical analysis** and **predictive modeling**. One notable example was developing a **regression model** to optimize our product pricing strategy. Using **Python** and **R**, I analyzed historical sales data and market trends, implementing **machine learning algorithms** to predict customer behavior. This resulted in a **15% increase** in product revenue and a **20% improvement** in customer retention rates. I also implemented **A/B testing frameworks** to validate our models, ensuring robust and reliable results that directly influenced product decisions.\"\n",
       "----- [END_DRAFT] -----\n",
       "\n",
       "[Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01X89h7qrLcaTUkth12Zcoqt`\n",
       "- content: `[{'citations': None, 'text': '----- [ANSWER_EVAL] -----\\n\\n**GOOD**\\n1. Shows confidence\\n2. Brief and to the point\\n\\n**BAD**\\n1. Extremely vague response lacking any specific examples\\n2. No mention of statistical analysis or predictive modeling\\n3. No demonstration of technical expertise\\n4. Missing concrete impact or results\\n5. Informal language inappropriate for senior role\\n6. No mention of product optimization\\n\\n[RESPONSE METRICS]\\n{\\n    \"Narrative Clarity\": 2.3,\\n    \"Strategic Thinking\": 1.8,\\n    \"Technical Expertise\": 0.5,\\n    \"Impact Demonstration\": 1.2,\\n    \"True to Question\": 1.7,\\n    \"Overall Competence\": 1.4\\n}\\n\\n----- [EDITED_DRAFT] -----\\n\"In my previous role at [Company], I led several significant projects involving **statistical analysis** and **predictive modeling**. One notable example was developing a **regression model** to optimize our product pricing strategy. Using **Python** and **R**, I analyzed historical sales data and market trends, implementing **machine learning algorithms** to predict customer behavior. This resulted in a **15% increase** in product revenue and a **20% improvement** in customer retention rates. I also implemented **A/B testing frameworks** to validate our models, ensuring robust and reliable results that directly influenced product decisions.\"\\n----- [END_DRAFT] -----\\n\\n[Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?', 'type': 'text'}]`\n",
       "- model: `claude-3-5-sonnet-20241022`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1854, 'output_tokens': 352}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01X89h7qrLcaTUkth12Zcoqt', content=[TextBlock(citations=None, text='----- [ANSWER_EVAL] -----\\n\\n**GOOD**\\n1. Shows confidence\\n2. Brief and to the point\\n\\n**BAD**\\n1. Extremely vague response lacking any specific examples\\n2. No mention of statistical analysis or predictive modeling\\n3. No demonstration of technical expertise\\n4. Missing concrete impact or results\\n5. Informal language inappropriate for senior role\\n6. No mention of product optimization\\n\\n[RESPONSE METRICS]\\n{\\n    \"Narrative Clarity\": 2.3,\\n    \"Strategic Thinking\": 1.8,\\n    \"Technical Expertise\": 0.5,\\n    \"Impact Demonstration\": 1.2,\\n    \"True to Question\": 1.7,\\n    \"Overall Competence\": 1.4\\n}\\n\\n----- [EDITED_DRAFT] -----\\n\"In my previous role at [Company], I led several significant projects involving **statistical analysis** and **predictive modeling**. One notable example was developing a **regression model** to optimize our product pricing strategy. Using **Python** and **R**, I analyzed historical sales data and market trends, implementing **machine learning algorithms** to predict customer behavior. This resulted in a **15% increase** in product revenue and a **20% improvement** in customer retention rates. I also implemented **A/B testing frameworks** to validate our models, ensuring robust and reliable results that directly influenced product decisions.\"\\n----- [END_DRAFT] -----\\n\\n[Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 1854; Out: 352; Cache create: 0; Cache read: 0; Total: 2206)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reply = \"Yeah, when I was working as a research analyst, it was pretty tight. Lots of people asked me some pretty hard questions and I, you know, I just crushed it\"\n",
    "c = chat(user_reply)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Mechanic – Inline `Gradio UI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'----- [ANSWER_EVAL] -----\\n\\n**GOOD**\\n1. Shows confidence\\n2. Brief and to the point\\n\\n**BAD**\\n1. Extremely vague response lacking any specific examples\\n2. No mention of statistical analysis or predictive modeling\\n3. No demonstration of technical expertise\\n4. Missing concrete impact or results\\n5. Informal language inappropriate for senior role\\n6. No mention of product optimization\\n\\n[RESPONSE METRICS]\\n{\\n    \"Narrative Clarity\": 2.3,\\n    \"Strategic Thinking\": 1.8,\\n    \"Technical Expertise\": 0.5,\\n    \"Impact Demonstration\": 1.2,\\n    \"True to Question\": 1.7,\\n    \"Overall Competence\": 1.4\\n}\\n\\n----- [EDITED_DRAFT] -----\\n\"In my previous role at [Company], I led several significant projects involving **statistical analysis** and **predictive modeling**. One notable example was developing a **regression model** to optimize our product pricing strategy. Using **Python** and **R**, I analyzed historical sales data and market trends, implementing **machine learning algorithms** to predict customer behavior. This resulted in a **15% increase** in product revenue and a **20% improvement** in customer retention rates. I also implemented **A/B testing frameworks** to validate our models, ensuring robust and reliable results that directly influenced product decisions.\"\\n----- [END_DRAFT] -----\\n\\n[Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access claudette messages\n",
    "response = c.content[0].text\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gradio\")\n",
    "\n",
    "context_file = Path('docs/analytics.md')\n",
    "context_media = context_file.read_text(encoding='utf-8')\n",
    "system_prompt = \"\"\"You are a helpful and concise assistant.\"\"\"\n",
    "model = claudette.models[2]\n",
    "\n",
    "chat = claudette.Chat(model, sp=system_prompt)\n",
    "response = chat(\"\"\"Can you come up with 10 realistic questions a hiring manager might ask in an opening interview?  the job title for this role is: SENIOR RESEARCH ANALYST,\n",
    "            Do not add any additional commentary, just list 10 questions only. Start each question with a new line starting like:\n",
    "                [Q1] ... \n",
    "                [Q2] ...\n",
    "                My resume is in the project docs, the core competencies for a senior analyst are below:\n",
    "                {context_media}\"\"\")\n",
    "\n",
    "def parse_response(text):\n",
    "    return f\"{text}\"\n",
    "\n",
    "def respond(user_message, history):\n",
    "    print(\"Messages received so far:\", user_message)  # Print to see outside gradio\n",
    "    c = chat(f'System message: {INTERVIEW_INSTRUCTIONS}, User: {user_message}')\n",
    "    next_response = parse_response(c.content[0].text)\n",
    "    return next_response\n",
    "\n",
    "chatbot = gr.ChatInterface(\n",
    "    fn=respond,\n",
    "    examples=[\"Hello Neo.. let's begin.\"],\n",
    "    theme=\"shivi/calm_seafoam\",\n",
    "    chatbot=gr.Chatbot(autoscroll=False),\n",
    ")\n",
    "\n",
    "chatbot.launch(inline=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all metadata for side panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- [ANSWER_EVAL] -----\n",
      "\n",
      "**GOOD**\n",
      "1. Shows confidence\n",
      "2. Brief and to the point\n",
      "\n",
      "**BAD**\n",
      "1. Extremely vague response lacking any specific examples\n",
      "2. No mention of statistical analysis or predictive modeling\n",
      "3. No demonstration of technical expertise\n",
      "4. Missing concrete impact or results\n",
      "5. Informal language inappropriate for senior role\n",
      "6. No mention of product optimization\n",
      "\n",
      "[RESPONSE METRICS]\n",
      "{\n",
      "    \"Narrative Clarity\": 2.3,\n",
      "    \"Strategic Thinking\": 1.8,\n",
      "    \"Technical Expertise\": 0.5,\n",
      "    \"Impact Demonstration\": 1.2,\n",
      "    \"True to Question\": 1.7,\n",
      "    \"Overall Competence\": 1.4\n",
      "}\n",
      "\n",
      "----- [EDITED_DRAFT] -----\n",
      "\"In my previous role at [Company], I led several significant projects involving **statistical analysis** and **predictive modeling**. One notable example was developing a **regression model** to optimize our product pricing strategy. Using **Python** and **R**, I analyzed historical sales data and market trends, implementing **machine learning algorithms** to predict customer behavior. This resulted in a **15% increase** in product revenue and a **20% improvement** in customer retention rates. I also implemented **A/B testing frameworks** to validate our models, ensuring robust and reliable results that directly influenced product decisions.\"\n",
      "----- [END_DRAFT] -----\n",
      "\n",
      "[Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?\n"
     ]
    }
   ],
   "source": [
    "response_text = c.content[0].text\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def parse_llm_response(response_text):\n",
    "    \"\"\"Parse LLM response text into structured components.\n",
    "    Args:\n",
    "        response_text (str): Raw text response from LLM containing formatted sections\n",
    "    Returns:\n",
    "        dict: Dictionary with keys:\n",
    "            - ANSWER_EVAL (str): Evaluation feedback on previous answer\n",
    "            - RESPONSE_METRICS (dict): Parsed metrics JSON or raw metrics text\n",
    "            - EDITED_DRAFT (str): Improved answer draft\n",
    "            - QUESTION (str): Next interview question\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"ANSWER_EVAL\": None,\n",
    "        \"RESPONSE_METRICS\": None,\n",
    "        \"EDITED_DRAFT\": None,\n",
    "        \"QUESTION\": None\n",
    "    }\n",
    "\n",
    "    if \"----- [ANSWER_EVAL] -----\" in response_text:\n",
    "        eval_start = response_text.find(\"----- [ANSWER_EVAL] -----\") + len(\"----- [ANSWER_EVAL] -----\")\n",
    "        eval_end = response_text.find(\"[RESPONSE METRICS]\") if \"[RESPONSE METRICS]\" in response_text else response_text.find(\"----- [EDITED_DRAFT] -----\")\n",
    "        if eval_end != -1:\n",
    "            result[\"ANSWER_EVAL\"] = response_text[eval_start:eval_end].strip()\n",
    "\n",
    "    if \"[RESPONSE METRICS]\" in response_text:\n",
    "        metrics_start = response_text.find(\"[RESPONSE METRICS]\") + len(\"[RESPONSE METRICS]\")\n",
    "        metrics_end = response_text.find(\"----- [EDITED_DRAFT] -----\")\n",
    "        if metrics_end != -1:\n",
    "            metrics_text = response_text[metrics_start:metrics_end].strip()\n",
    "            try:\n",
    "                json_str = metrics_text[metrics_text.find(\"{\"):metrics_text.rfind(\"}\")+1]\n",
    "                import json\n",
    "                result[\"RESPONSE_METRICS\"] = json.loads(json_str)\n",
    "            except:\n",
    "                result[\"RESPONSE_METRICS\"] = metrics_text\n",
    "\n",
    "    if \"----- [EDITED_DRAFT] -----\" in response_text:\n",
    "        draft_start = response_text.find(\"----- [EDITED_DRAFT] -----\") + len(\"----- [EDITED_DRAFT] -----\")\n",
    "        draft_end = response_text.find(\"----- [END_DRAFT] -----\")\n",
    "        if draft_end != -1:\n",
    "            result[\"EDITED_DRAFT\"] = response_text[draft_start:draft_end].strip()\n",
    "\n",
    "    if \"----- [END_DRAFT] -----\" in response_text:\n",
    "        q_start = response_text.find(\"----- [END_DRAFT] -----\") + len(\"----- [END_DRAFT] -----\")\n",
    "        result[\"QUESTION\"] = response_text[q_start:].strip()\n",
    "        \n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### > [Q2] How have you approached hypothesis testing and A/B experiments in your previous roles? Can you share a specific example?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**GOOD**\n",
       "1. Shows confidence\n",
       "2. Brief and to the point\n",
       "\n",
       "**BAD**\n",
       "1. Extremely vague response lacking any specific examples\n",
       "2. No mention of statistical analysis or predictive modeling\n",
       "3. No demonstration of technical expertise\n",
       "4. Missing concrete impact or results\n",
       "5. Informal language inappropriate for senior role\n",
       "6. No mention of product optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Metric               |   Value |\n",
       "|:---------------------|--------:|\n",
       "| Narrative Clarity    |     2.3 |\n",
       "| Strategic Thinking   |     1.8 |\n",
       "| Technical Expertise  |     0.5 |\n",
       "| Impact Demonstration |     1.2 |\n",
       "| True to Question     |     1.7 |\n",
       "| Overall Competence   |     1.4 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"In my previous role at [Company], I led several significant projects involving **statistical analysis** and **predictive modeling**. One notable example was developing a **regression model** to optimize our product pricing strategy. Using **Python** and **R**, I analyzed historical sales data and market trends, implementing **machine learning algorithms** to predict customer behavior. This resulted in a **15% increase** in product revenue and a **20% improvement** in customer retention rates. I also implemented **A/B testing frameworks** to validate our models, ensuring robust and reliable results that directly influenced product decisions.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsed = parse_llm_response(response_text)\n",
    "question = parsed[\"QUESTION\"]\n",
    "\n",
    "# Access other sections as needed\n",
    "eval_section = parsed[\"ANSWER_EVAL\"]\n",
    "metrics = parsed[\"RESPONSE_METRICS\"]\n",
    "draft = parsed[\"EDITED_DRAFT\"]\n",
    "\n",
    "eval_section = parsed[\"ANSWER_EVAL\"]\n",
    "display(Markdown(f\"### > {question}\"))\n",
    "display(Markdown(eval_section))\n",
    "display(Markdown(pd.DataFrame(list(metrics.items()), columns=['Metric', 'Value']).to_markdown(index=False)))\n",
    "display(Markdown(draft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Gamification Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ANSWER EVAL -----\n",
      "• Claims success in research analyst role\n",
      "• No specific examples provided\n",
      "• Extremely vague response\n",
      "• No mention of hypothesis testing or A/B experiments\n",
      "\n",
      "**GOOD**\n",
      "1. Shows confidence (albeit misplaced)\n",
      "\n",
      "**BAD**\n",
      "1. Complete lack of technical detail\n",
      "2. No actual example provided\n",
      "3. Informal and unprofessional language\n",
      "4. Failed to demonstrate any understanding of A/B testing\n",
      "5. Missing methodology, results, or impact\n",
      "6. Colloquial language inappropriate for senior role\n",
      "\n",
      "[RESPONSE METRICS]\n",
      "{\n",
      "    \"Linguistic_Clarity\": 2.3,\n",
      "    \"Confidence\": 6.8,\n",
      "    \"Technical_Expertise\": 0.5,\n",
      "    \"Strategic_Thinking\": 1.2,\n",
      "    \"Impact_Demonstration\": 0.8,\n",
      "    \"Industry_Understanding\": 1.4\n",
      "}\n",
      "\n",
      "----- [EDITED_DRAFT] -----\n",
      "\"I led a significant **A/B testing initiative** for our e-commerce platform's checkout process. We hypothesized that a simplified form would increase conversion rates. Using a **statistical significance level** of 95%, we tested two variants across 50,000 users over three weeks. The experiment revealed a **23% increase** in checkout completions with the new design, leading to approximately $2.1M in additional annual revenue. We used **chi-square testing** to validate our results and implemented comprehensive tracking to ensure data accuracy.\"\n",
      "[END_DRAFT]\n",
      "\n",
      "[Q3] Describe your approach to data quality assurance and how you ensure the integrity of the insights you provide.\n"
     ]
    }
   ],
   "source": [
    "print(c.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json \n",
    "\n",
    "def extract_metrics(c):\n",
    "    s1 = (c.content[0].text.split('[RESPONSE METRICS]')[1])\n",
    "    s2 = s1.split(\"}\")[0] + \"}\"\n",
    "    return json.loads(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Narrative Clarity': 2.3,\n",
       " 'Strategic Thinking': 1.8,\n",
       " 'Technical Expertise': 0.5,\n",
       " 'Impact Demonstration': 1.2,\n",
       " 'True to Question': 1.7,\n",
       " 'Overall Competence': 1.4}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpis = extract_metrics(c)\n",
    "kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7883\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dashboard(initial_metrics=None):\n",
    "    initial_metrics = initial_metrics or {}\n",
    "    \n",
    "    with gr.Blocks() as demo:\n",
    "        # Dict to store all number components\n",
    "        number_components = {}\n",
    "        \n",
    "        # Create all metrics in a single row\n",
    "        with gr.Row():\n",
    "            for metric_name, value in initial_metrics.items():\n",
    "                number_components[metric_name] = gr.Number(\n",
    "                    label=metric_name,\n",
    "                    value=value,  # Use the original value without rounding\n",
    "                    precision=1,  # Set display precision to 1 decimal\n",
    "                    info=\"rating/10\"\n",
    "                )\n",
    "        \n",
    "        # Function to update metrics\n",
    "        def update_metrics(new_metrics):\n",
    "            # Create any new metrics that didn't exist before\n",
    "            for metric_name in new_metrics:\n",
    "                if metric_name not in number_components:\n",
    "                    with gr.Row():\n",
    "                        number_components[metric_name] = gr.Number(\n",
    "                            label=metric_name,\n",
    "                            value=new_metrics[metric_name],\n",
    "                            precision=2,  # Set display precision\n",
    "                            info=\"rating/10\"\n",
    "                        )\n",
    "            \n",
    "            # Update all existing metrics\n",
    "            return [comp.update(value=new_metrics.get(k, 0.0)) for k, comp in number_components.items()]\n",
    "    \n",
    "    return demo, update_metrics, number_components\n",
    "\n",
    "demo, update_metrics, components = create_dashboard(kpis)\n",
    "demo.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wingman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
